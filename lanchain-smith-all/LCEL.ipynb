{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('/home/prakhar-tiwari/Desktop/myProjects/AI-Learn/LangChain/lanchain-smith-all/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://localhost:11434\"\n",
    "model_name = \"llama3.2:1b\"\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "  base_url = base_url,\n",
    "    model = model_name,\n",
    "    temperature = 0.8,\n",
    "    num_predict = 256,\n",
    "    # other params ...\n",
    ")\n",
    "\n",
    "systemMessage = \"You are vegeta behave like him , give ans of asked ques in very arrogant way and short way\"\n",
    "\n",
    "humanMessage = \"how are you , goku is strongest sayain\"\n",
    "message = [systemMessage , humanMessage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate)\n",
    "system = SystemMessagePromptTemplate.from_template(\" yu are {school} teacher , behave and give answer like them\")\n",
    "question = HumanMessagePromptTemplate.from_template(\" please give me about {topic} in {line} sentences\")\n",
    "\n",
    "message = [system, question]\n",
    "template = ChatPromptTemplate(message)\n",
    "\n",
    "# question = template.invoke({\"school\": \"phd\" , \"topic\": \"sun\" , \"line\": \"5\"})\n",
    "# response = llm.invoke(question)\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My dear student, the sun is a massive ball of hot, glowing gas that is the center of our solar system, accounting for 99.8% of the mass within it. It is a G-type main-sequence star, meaning it is in the middle of its life cycle and fusing hydrogen into helium in its core. The sun's surface temperature is about 5,500 degrees Celsius, while its core is a scorching 15,000,000 degrees Celsius, making it one of the most inhospitable places in the universe. The sun's energy output is what makes life on Earth possible, and it is what drives our planet's climate, weather patterns, and natural cycles. If the sun were to go dark, life as we know it would come to an end, at least for a while, but fortunately, its fuel will eventually be depleted in about 5 billion years.\n"
     ]
    }
   ],
   "source": [
    "# now how to use chain\n",
    "\n",
    "#chain = template | llm\n",
    "\n",
    "# response = chain.invoke({\"school\": \"phd\" , \"topic\": \"sun\" , \"line\": \"5\"})\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first chain individual\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = template | llm | StrOutputParser()  # it should be in correct format or correct alignment\n",
    "# response = chain.invoke({\"school\": \"phd\" , \"topic\": \"sun\" , \"line\": \"5\"})\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_chain individual\n",
    "\n",
    "analysis_prompt = ChatPromptTemplate.from_template(''' analyze the output coming from prev chain {response}\n",
    "                                                   how diffcult is for phd teacher\n",
    "                                                   ''')\n",
    "\n",
    "#second_chain = analysis_prompt | llm | StrOutputParser()\n",
    "# output = second_chain.invoke({'response': response, \"school\":\"phd\"})\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the output from your previous chain, I'd rate it as relatively straightforward and accessible to a PhD-level student. Here's why:\n",
      "\n",
      "1. **Technical vocabulary**: While some specialized terms like \"emergent property,\" \"red giant,\" and \"main-sequence star\" might be unfamiliar, they are still within the realm of general knowledge.\n",
      "2. **Contextual understanding**: The text provides a clear overview of the sun's characteristics, its place in our solar system, and its role in driving Earth's climate and weather patterns. This contextual understanding is essential for comprehension, even if the technical details might not be new or uninteresting to you.\n",
      "3. **Scientific concepts**: The text covers fundamental scientific concepts, such as:\n",
      "\t* The sun's mass and distance from Earth\n",
      "\t* Its surface temperature and energy output (in terms of electromagnetic radiation)\n",
      "\t* The sun's evolution over its 4.6 billion-year history\n",
      "\t* Its eventual expansion into a red giant in about 5 billion years\n",
      "\n",
      "These topics are likely to be familiar to PhD students in astrophysics, planetary science, or related fields.\n",
      "\n",
      "However, it's essential to note that some phrases might require more background knowledge or specialized context, such as:\n",
      "\n",
      "1. **Terminology\n"
     ]
    }
   ],
   "source": [
    "#combined_chain\n",
    "\n",
    "combined_chain = {\"response\": chain} | analysis_prompt | llm | StrOutputParser()\n",
    "output = combined_chain.invoke({\"school\": \"phd\" , \"topic\": \"sun\" , \"line\": \"5\"})\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myAIEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
