{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUTPIT PARSING..\n",
    "\n",
    "1. StrOutputParser()\n",
    "2. jsonOutputParser()\n",
    "3. Csv output parser()\n",
    "4. Datatime output parser()\n",
    "5. structure outputParser()\n",
    "6. pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pydantic parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('/home/prakhar-tiwari/Desktop/myProjects/AI-Learn/LangChain/lanchain-smith-all/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://localhost:11434\"\n",
    "model_name = \"llama3.2:1b\"\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "  base_url = base_url,\n",
    "    model = model_name,\n",
    "    temperature = 0.8,\n",
    "    num_predict = 256,\n",
    "    # other params ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  typing import Optional\n",
    "from pydantic import BaseModel , Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser,JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "  \"\"\" joke  to tell user\"\"\"                             # BaseModel is used for validation and it is some kind of superset where all other class have to use\n",
    "  setup: str = Field(description= \"the setup of joke\")\n",
    "  punchline: str = Field(description = \"the punchline of the joke\")\n",
    "  rating: Optional[int] = Field(description = \"The rating of joke  is frpm 1 to 10 \", default =None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='//{\"setup\": \"In a distant future, Goku traveled through space with his dog. They were on their way to Earth when they got lost in the forest.\", \\n\"punchline\": \"To get back home, they had to fight many powerful enemies and obtain the Dragon Ball of Death.\", \\n\"rating\": 8}' additional_kwargs={} response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-05-15T19:23:22.501394624Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2387763740, 'load_duration': 22412676, 'prompt_eval_count': 302, 'prompt_eval_duration': 34315642, 'eval_count': 68, 'eval_duration': 2330320169, 'model_name': 'llama3.2:1b'} id='run--650c0d7d-3570-4e72-abea-e21ea07c8d8a-0' usage_metadata={'input_tokens': 302, 'output_tokens': 68, 'total_tokens': 370}\n"
     ]
    }
   ],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "  template = '''\n",
    "  Answer the query with joke , here is  your formatting instruction.\n",
    "  {format_instruction}\n",
    "\n",
    "  Query : {query}\n",
    "  Answer:''',\n",
    "  input_variables=['query'],\n",
    "  partial_variables = {'format_instruction': parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "output = chain.invoke({'query': 'tell me a joke of goku'}) # have to use ollama:3.2 b wla\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION SECOND\n",
    "# with structured output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='cat' punchline='Why did the cat join a band? Because it wanted to be the purr-cussionist.' rating=None\n"
     ]
    }
   ],
   "source": [
    "llm1 = llm.with_structured_output(Joke)\n",
    "output = llm1.invoke('tell me a joke of cat')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSONOUTPUT PARSER \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\\n  \"foo\": [\\n    \"\\\\\"It\\'s over 9,000!!\\\\\"\"\\n  ]\\n}' additional_kwargs={} response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-05-15T19:23:37.526806886Z', 'done': True, 'done_reason': 'stop', 'total_duration': 804021317, 'load_duration': 19840431, 'prompt_eval_count': 302, 'prompt_eval_duration': 35256428, 'eval_count': 22, 'eval_duration': 748293319, 'model_name': 'llama3.2:1b'} id='run--e3fd3456-8758-425b-8bc5-aaa360923c11-0' usage_metadata={'input_tokens': 302, 'output_tokens': 22, 'total_tokens': 324}\n"
     ]
    }
   ],
   "source": [
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "  template = '''\n",
    "  Answer the query with joke , here is  your formatting instruction.\n",
    "  {format_instruction}\n",
    "\n",
    "  Query : {query}\n",
    "  Answer:''',\n",
    "  input_variables=['query'],\n",
    "  partial_variables = {'format_instruction': parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "output = chain.invoke({'query': 'tell me a joke of goku'}) # have to use ollama:3.2 b wla\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myAIEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
